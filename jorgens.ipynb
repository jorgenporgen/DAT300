{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import os\n",
    "\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask_ml.linear_model import LogisticRegression\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from dask_ml.datasets import make_classification\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask_ml.model_selection import IncrementalSearchCV\n",
    "import dask_ml.datasets\n",
    "import dask_ml.cluster\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle and preprocess data\n",
    "X = feature_array\n",
    "y = target_array.flatten()\n",
    "\n",
    "# Split data into train and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Scale data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "# Transform (standardise) both X_train and X_test with mean and STD from\n",
    "# training data\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty': ['l1', 'l2'], 'C': [0.5, 1, 2]}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "tuned_lr = GridSearchCV(lr, parameters)\n",
    "\n",
    "with ProgressBar():\n",
    "    tuned_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the score\n",
    "pd.DataFrame(tuned_lr.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hyperparameters of best performing model\n",
    "tuned_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the best classifier\n",
    "clf = tuned_lr.best_params_\n",
    "print(clf)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Test accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Scikit-Learn Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, random_state=0)\n",
    "X[:5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a support vector machine (SVC) model using grid search\n",
    "param_grid = {\"C\": [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "              \"kernel\": ['rbf', 'poly', 'sigmoid'],\n",
    "              \"shrinking\": [True, False]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(gamma='auto', random_state=0, probability=True),\n",
    "                           param_grid=param_grid,\n",
    "                           return_train_score=False,\n",
    "                           iid=True,\n",
    "                           cv=3,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model using cluster or joblib\n",
    "with joblib.parallel_backend('dask'):\n",
    "    grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.predict(X)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on large data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some random dask arrays\n",
    "X, y = dask_ml.datasets.make_blobs(n_samples=10000000,\n",
    "                                   chunks=1000000,\n",
    "                                   random_state=0,\n",
    "                                   centers=3)\n",
    "X = X.persist()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a support vector machine model (SVC) using grid search optimization\n",
    "param_grid = {\"C\": [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "              \"kernel\": ['rbf', 'poly', 'sigmoid'],\n",
    "              \"shrinking\": [True, False]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(gamma='auto', random_state=0, probability=True),\n",
    "                           param_grid=param_grid,\n",
    "                           return_train_score=False,\n",
    "                           iid=True,\n",
    "                           cv=3,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(data, labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine model\n",
    "\n",
    "# Train linear SVC\n",
    "svm_linear = SVC(kernel='linear', random_state=1, C=1.0)\n",
    "svm_linear.fit(X, y)\n",
    "\n",
    "# Train non-linear SVC with RBF kernel\n",
    "svm_nonLinear = SVC(kernel='rbf', random_state=1, gamma=0.10, C=10.0)\n",
    "svm_nonLinear.fit(X_xor, y_xor)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GridSearchCV to tune hyperparameters\n",
    "parameters = {'penalty': ['l1', 'l2'], 'C': [0.5, 1, 2]}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "tuned_lr = GridSearchCV(lr, parameters)\n",
    "\n",
    "with ProgressBar():\n",
    "    tuned_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results of GridSearchCV\n",
    "pd.DataFrame(tuned_lr.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hyperparameters of best performing model\n",
    "tuned_lr.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
